{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "import pandas as pd \n",
    "from torch.nn import Linear, ReLU, BCELoss, Conv2d, Module, Sigmoid\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    \n",
    "    #get rid of black images\n",
    "    df.drop(df[df['Image'].map(np.max) == 0].index,inplace=True)\n",
    "    \n",
    "    #get rid of rgb images\n",
    "    def func(img):\n",
    "        if len(img.shape)>2:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    df.drop(df[df['Image'].map(func)].index,inplace=True)\n",
    "    \n",
    "    \n",
    "    #process all the available images; to grayscale,60*60,normalize,proper dimension for pytorch \n",
    "    def processImage(px_data):\n",
    "        \n",
    "        px_data_scaled = px_data / px_data.max()\n",
    "        px_data_scaled = resize(px_data, (60, 60), anti_aliasing=True)\n",
    "        px_data_scaled = px_data_scaled[None,:,:]\n",
    "        return px_data_scaled    \n",
    "    \n",
    "    \n",
    "    df.loc[:,'Image']=df.apply(lambda x: processImage(x['Image']), axis=1)\n",
    "    \n",
    "    #make the labels into bool Alive is True\n",
    "    df.loc[:,'label'] = df['label'].map(lambda x: x == 'Alive')\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Pet images dataset.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_dataframe(df):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            petimages : PetImages -- The PetImages object containing the images.\n",
    "        kwargs:\n",
    "            size : int -- the size of the canonicalized images.\n",
    "        \"\"\"\n",
    "        data = torch.as_tensor(np.array(df['Image'].tolist(),dtype=np.float32))\n",
    "        labels = np.array(df['label'],dtype=np.int8)[:,None]\n",
    "\n",
    "        \n",
    "        return Dataset(data, labels)\n",
    "\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        # Don't change the constructor\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Return the number of images in the dataset.\n",
    "        \"\"\"\n",
    "        return self.data.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Return the element corresponding to idx.\n",
    "        \n",
    "        args:\n",
    "            idx : int -- the index of the sample to return\n",
    "            \n",
    "        returns: Dict -- A dictionary with two elements; \"label\" and \"image\". \"label\" has the associated label\n",
    "            and \"image\" is a (size, size, 3)\n",
    "        \"\"\"\n",
    "        # Convert it to a regular python int.\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        return {'label':self.labels[idx],'image':self.data[idx]}\n",
    "    \n",
    "def Dataset_load(df):\n",
    "    return Dataset.from_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(dataset):\n",
    "    \"\"\" Split pet into train and test sets.\n",
    "    \n",
    "    args:\n",
    "        pet : PetDataset -- the PetDataset instance to split.\n",
    "\n",
    "    kwargs:\n",
    "        train_count: The number of elements in the training set. The remainder should be in the test set.\n",
    "    \n",
    "    return: List[Dataset] -- the list of [train, test] datasets.\n",
    "    \"\"\"\n",
    "    total = len(dataset)\n",
    "    test = int(np.ceil(0.2*total))\n",
    "    train = total-test\n",
    "\n",
    "    \n",
    "    return torch.utils.data.random_split(dataset,[train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 12, 5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc1   = nn.Linear(37632, 1)\n",
    "        self.sigm1 = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, X, debug=False):\n",
    "        if debug: print(f\"Input Shape: {X.shape}\")\n",
    "\n",
    "        X = self.relu1(self.conv1(X))\n",
    "        if debug: print(f\"Conv1 Shape: {X.shape}\")\n",
    "\n",
    "        X = X.view(X.size(0), -1) # Flatten the shape\n",
    "        if debug: print(f\"Flattened Shape: {X.shape}\")\n",
    "\n",
    "        X = self.sigm1(self.fc1(X))\n",
    "        if debug: print(f\"Output Shape: {X.shape}\")\n",
    "\n",
    "        return X\n",
    "\n",
    "def count_parameters(model):\n",
    "    # Count all trainable parameters,\n",
    "    # from https://discuss.pytorch.org/t/how-do-i-check-the-number-of-parameters-of-a-model/4325/9\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, train_dataset, epochs=25, batch_size=500):\n",
    "    \"\"\" Train the model on data\n",
    "    \"\"\"\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "#     pass # TODO: Set up\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch in range(epochs):\n",
    "        # If you add the training loss to this variable, it will be printed for you\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for data in train_dataloader:\n",
    "            output = model(data['image'])\n",
    "            loss = criterion(output,data['label'].float())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            epoch_loss+= loss.item()\n",
    "#         pass # TODO:Process all data for each epoch\n",
    "\n",
    "        epoch += 1\n",
    "        if epoch % 50 == 0:\n",
    "            curr_time = time.perf_counter() - start_time\n",
    "            print(f'[{curr_time:6.1f}/{curr_time/epoch*epochs:6.1f}] Epoch {epoch: <3d} loss: {epoch_loss / len(train_dataloader)} acc: {test_model(model, train_dataset)}')\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_data, batch_size=500):\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "    num_correct = 0\n",
    "    num_alive = 0\n",
    "    num_alive_correct = 0\n",
    "    num_dead = 0\n",
    "    num_dead_correct = 0\n",
    "    for data in test_dataloader:\n",
    "        y_pred = model(data[\"image\"]).round()\n",
    "        y_actual = data[\"label\"].float()\n",
    "        num_correct += (y_pred == y_actual).sum()\n",
    "        for ya,yp in zip(y_actual,y_pred):\n",
    "            if ya == 1.0:\n",
    "                num_alive+=1\n",
    "                if yp == 1.0:\n",
    "                    num_alive_correct+=1\n",
    "            else:\n",
    "                num_dead+=1\n",
    "                if yp ==0.0:\n",
    "                    num_dead_correct+=1\n",
    "    print(num_dead,num_alive)\n",
    "    return num_correct.item() / len(test_data),(num_alive_correct/num_alive),(num_dead_correct/num_dead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1840\n",
      "249 1223\n",
      "[ 128.8/1288.5] Epoch 50  loss: 0.3350102995832761 acc: (0.8702445652173914, 0.9918233851185609, 0.27309236947791166)\n",
      "249 1223\n",
      "[ 259.4/1297.1] Epoch 100 loss: 0.2527327803273996 acc: (0.90625, 0.9869174161896974, 0.5100401606425703)\n",
      "249 1223\n",
      "[ 390.2/1300.5] Epoch 150 loss: 0.19161243960261345 acc: (0.9327445652173914, 0.9811937857726901, 0.6947791164658634)\n",
      "249 1223\n",
      "[ 520.3/1300.9] Epoch 200 loss: 0.1583006960650285 acc: (0.9578804347826086, 0.9901880621422731, 0.7991967871485943)\n",
      "249 1223\n",
      "[ 651.0/1302.0] Epoch 250 loss: 0.12499107060333094 acc: (0.970108695652174, 0.9893704006541292, 0.8755020080321285)\n",
      "249 1223\n",
      "[ 781.3/1302.2] Epoch 300 loss: 0.09667768155535063 acc: (0.9802989130434783, 0.9942763695829926, 0.9116465863453815)\n",
      "249 1223\n",
      "[ 911.7/1302.4] Epoch 350 loss: 0.07481369568655888 acc: (0.985733695652174, 0.9959116925592805, 0.9357429718875502)\n",
      "249 1223\n",
      "[1042.2/1302.7] Epoch 400 loss: 0.05849616297831138 acc: (0.9891304347826086, 0.9967293540474244, 0.9518072289156626)\n",
      "249 1223\n",
      "[1173.3/1303.7] Epoch 450 loss: 0.06987619039913019 acc: (0.9904891304347826, 0.9983646770237122, 0.9518072289156626)\n",
      "249 1223\n",
      "[1304.2/1304.2] Epoch 500 loss: 0.06361363989611467 acc: (0.9918478260869565, 1.0, 0.9518072289156626)\n",
      "Done.\n",
      "249 1223\n",
      "Train accuracy: 0.9918478260869565 Alive accuracy: 1.0 Dead accuracy: 0.9518072289156626\n",
      "87 281\n",
      "Test accuracy: 0.8614130434782609 Alive accuracy: 0.9395017793594306 Dead accuracy: 0.6091954022988506\n"
     ]
    }
   ],
   "source": [
    "def trainModel(filename,epoch,batchsize):\n",
    "    train_df = pd.read_pickle(filename)\n",
    "    df_train = process(train_df)\n",
    "    print(len(df_train))\n",
    "    ds = Dataset_load(df_train)\n",
    "    train_data, valid_data = tuple(split(ds))\n",
    "\n",
    "    model = Model()\n",
    "\n",
    "    training_loop(model, train_data,epochs = epoch,batch_size = batchsize)\n",
    "\n",
    "    train_acc,alive_acc,dead_acc = test_model(model, train_data)\n",
    "    print(f\"Train accuracy: {train_acc} Alive accuracy: {alive_acc} Dead accuracy: {dead_acc}\")\n",
    "\n",
    "    test_acc,talive_acc,tdead_acc = test_model(model, valid_data)\n",
    "    print(f\"Test accuracy: {test_acc} Alive accuracy: {talive_acc} Dead accuracy: {tdead_acc}\")\n",
    "    \n",
    "    return model,train_data,valid_data\n",
    "    \n",
    "myModel,_,_ = trainModel(\"train_csv.pkl\",500,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465\n",
      "24 441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.853763440860215, 0.9002267573696145, 0.0)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_pickle('test_data.pkl')\n",
    "df_test = process(test_df)\n",
    "print(len(df_test))\n",
    "ds = Dataset_load(df_test)\n",
    "test_model(myModel,ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
