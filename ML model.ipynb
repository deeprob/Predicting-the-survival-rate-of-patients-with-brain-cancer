{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "import pandas as pd \n",
    "from torch.nn import Linear, ReLU, BCELoss, Conv2d, Module, Sigmoid\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    \n",
    "    #get rid of black images\n",
    "    df.drop(df[df['Image'].map(np.max) == 0].index,inplace=True)\n",
    "    \n",
    "    #get rid of rgb images\n",
    "    def func(img):\n",
    "        if len(img.shape)>2:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    df.drop(df[df['Image'].map(func)].index,inplace=True)\n",
    "    \n",
    "    \n",
    "    #process all the available images; to grayscale,60*60,normalize,proper dimension for pytorch \n",
    "    def processImage(px_data):\n",
    "        \n",
    "        px_data_scaled = px_data / px_data.max()\n",
    "        px_data_scaled = resize(px_data, (60, 60), anti_aliasing=True)\n",
    "        px_data_scaled = px_data_scaled[None,:,:]\n",
    "        return px_data_scaled    \n",
    "    \n",
    "    \n",
    "    df.loc[:,'Image']=df.apply(lambda x: processImage(x['Image']), axis=1)\n",
    "    \n",
    "    #make the labels into bool Alive is True\n",
    "    df.loc[:,'label'] = df['label'].map(lambda x: x == 'Alive')\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Pet images dataset.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_dataframe(df):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            petimages : PetImages -- The PetImages object containing the images.\n",
    "        kwargs:\n",
    "            size : int -- the size of the canonicalized images.\n",
    "        \"\"\"\n",
    "        data = torch.as_tensor(np.array(df['Image'].tolist(),dtype=np.float32))\n",
    "        labels = np.array(df['label'],dtype=np.int8)[:,None]\n",
    "\n",
    "        \n",
    "        return Dataset(data, labels)\n",
    "\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        # Don't change the constructor\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Return the number of images in the dataset.\n",
    "        \"\"\"\n",
    "        return self.data.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Return the element corresponding to idx.\n",
    "        \n",
    "        args:\n",
    "            idx : int -- the index of the sample to return\n",
    "            \n",
    "        returns: Dict -- A dictionary with two elements; \"label\" and \"image\". \"label\" has the associated label\n",
    "            and \"image\" is a (size, size, 3)\n",
    "        \"\"\"\n",
    "        # Convert it to a regular python int.\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        return {'label':self.labels[idx],'image':self.data[idx]}\n",
    "    \n",
    "def Dataset_load(df):\n",
    "    return Dataset.from_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(dataset):\n",
    "    \"\"\" Split pet into train and test sets.\n",
    "    \n",
    "    args:\n",
    "        pet : PetDataset -- the PetDataset instance to split.\n",
    "\n",
    "    kwargs:\n",
    "        train_count: The number of elements in the training set. The remainder should be in the test set.\n",
    "    \n",
    "    return: List[Dataset] -- the list of [train, test] datasets.\n",
    "    \"\"\"\n",
    "    total = len(dataset)\n",
    "    test = int(np.ceil(0.2*total))\n",
    "    train = total-test\n",
    "\n",
    "    \n",
    "    return torch.utils.data.random_split(dataset,[train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 12, 5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.avg1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(12, 30, 5)\n",
    "        self.tanh2 = nn.Tanh()\n",
    "        self.avg2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1   = nn.Linear(4320, 1)\n",
    "        self.sigm1 = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, X, debug=False):\n",
    "        if debug: print(f\"Input Shape: {X.shape}\")\n",
    "\n",
    "        X = self.avg1(self.relu1(self.conv1(X)))\n",
    "        if debug: print(f\"Conv1 Shape: {X.shape}\")\n",
    "            \n",
    "        X = self.avg2(self.tanh2(self.conv2(X)))\n",
    "        if debug: print(f\"Conv1 Shape: {X.shape}\")\n",
    "\n",
    "        X = X.view(X.size(0), -1) # Flatten the shape\n",
    "        if debug: print(f\"Flattened Shape: {X.shape}\")\n",
    "\n",
    "        X = self.sigm1(self.fc1(X))\n",
    "        if debug: print(f\"Output Shape: {X.shape}\")\n",
    "\n",
    "        return X\n",
    "\n",
    "def count_parameters(model):\n",
    "    # Count all trainable parameters,\n",
    "    # from https://discuss.pytorch.org/t/how-do-i-check-the-number-of-parameters-of-a-model/4325/9\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([5, 1, 60, 60])\n",
      "Conv1 Shape: torch.Size([5, 12, 28, 28])\n",
      "Conv1 Shape: torch.Size([5, 30, 12, 12])\n",
      "Flattened Shape: torch.Size([5, 4320])\n",
      "Output Shape: torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "mM = Model()\n",
    "X = torch.zeros(5,1,60,60)\n",
    "y = mM(X,debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, train_dataset, epochs=25, batch_size=500):\n",
    "    \"\"\" Train the model on data\n",
    "    \"\"\"\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "#     pass # TODO: Set up\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch in range(epochs):\n",
    "        # If you add the training loss to this variable, it will be printed for you\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for data in train_dataloader:\n",
    "            output = model(data['image'])\n",
    "            loss = criterion(output,data['label'].float())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            epoch_loss+= loss.item()\n",
    "#         pass # TODO:Process all data for each epoch\n",
    "\n",
    "        epoch += 1\n",
    "        if epoch % 50 == 0:\n",
    "            curr_time = time.perf_counter() - start_time\n",
    "            print(f'[{curr_time:6.1f}/{curr_time/epoch*epochs:6.1f}] Epoch {epoch: <3d} loss: {epoch_loss / len(train_dataloader)} acc: {test_model(model, train_dataset)}')\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_data, batch_size=500):\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "    num_correct = 0\n",
    "    num_alive = 0\n",
    "    num_alive_correct = 0\n",
    "    num_dead = 0\n",
    "    num_dead_correct = 0\n",
    "    for data in test_dataloader:\n",
    "        y_pred = model(data[\"image\"]).round()\n",
    "        y_actual = data[\"label\"].float()\n",
    "        num_correct += (y_pred == y_actual).sum()\n",
    "        for ya,yp in zip(y_actual,y_pred):\n",
    "            if ya == 1.0:\n",
    "                num_alive+=1\n",
    "                if yp == 1.0:\n",
    "                    num_alive_correct+=1\n",
    "            else:\n",
    "                num_dead+=1\n",
    "                if yp ==0.0:\n",
    "                    num_dead_correct+=1\n",
    "    print(num_dead,num_alive)\n",
    "    return num_correct.item() / len(test_data),(num_alive_correct/num_alive),(num_dead_correct/num_dead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4345\n",
      "534 2942\n",
      "[ 507.8/2031.1] Epoch 50  loss: 0.36179090567997524 acc: (0.8644994246260069, 0.9938817131203264, 0.15168539325842698)\n",
      "534 2942\n",
      "[1139.3/2278.6] Epoch 100 loss: 0.3191119134426117 acc: (0.8780207134637514, 0.9942216179469748, 0.23782771535580524)\n",
      "534 2942\n",
      "[1594.3/2125.8] Epoch 150 loss: 0.2859384949718203 acc: (0.8866513233601842, 0.9935418082936778, 0.29775280898876405)\n",
      "534 2942\n",
      "[2037.6/2037.6] Epoch 200 loss: 0.256148675935609 acc: (0.8944188722669736, 0.9928619986403807, 0.352059925093633)\n",
      "Done.\n",
      "534 2942\n",
      "Train accuracy: 0.8944188722669736 Alive accuracy: 0.9928619986403807 Dead accuracy: 0.352059925093633\n",
      "136 733\n",
      "Test accuracy: 0.8734177215189873 Alive accuracy: 0.975443383356071 Dead accuracy: 0.3235294117647059\n"
     ]
    }
   ],
   "source": [
    "def trainModel(filename,epoch,batchsize):\n",
    "    train_df = pd.read_pickle(filename)\n",
    "    df_train = process(train_df)\n",
    "    print(len(df_train))\n",
    "    ds = Dataset_load(df_train)\n",
    "    train_data, valid_data = tuple(split(ds))\n",
    "\n",
    "    model = Model()\n",
    "\n",
    "    training_loop(model, train_data,epochs = epoch,batch_size = batchsize)\n",
    "\n",
    "    train_acc,alive_acc,dead_acc = test_model(model, train_data)\n",
    "    print(f\"Train accuracy: {train_acc} Alive accuracy: {alive_acc} Dead accuracy: {dead_acc}\")\n",
    "\n",
    "    test_acc,talive_acc,tdead_acc = test_model(model, valid_data)\n",
    "    print(f\"Test accuracy: {test_acc} Alive accuracy: {talive_acc} Dead accuracy: {tdead_acc}\")\n",
    "    \n",
    "    return model,train_data,valid_data\n",
    "    \n",
    "myModel,_,_ = trainModel(\"train_csv.pkl\",100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088\n",
      "177 911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8529411764705882, 0.9681668496158068, 0.2598870056497175)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_pickle('test_data.pkl')\n",
    "df_test = process(test_df)\n",
    "print(len(df_test))\n",
    "ds = Dataset_load(df_test)\n",
    "test_model(myModel,ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
