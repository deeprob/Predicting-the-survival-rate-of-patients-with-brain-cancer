{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook shows the entire data collection pipeline for this project using a single collection TCGA-LGG from the TCIA archive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import io\n",
    "import pydicom\n",
    "import tqdm\n",
    "from pydicom import dcmread\n",
    "from pydicom.filebase import DicomBytesIO\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Cancer Imaging Archive (TCIA) is a service which de-identifies and hosts a large archive of medical images of cancer accessible for public download. The data are organized as “collections”; typically patients’ imaging related by a common disease (e.g. lung cancer), image modality or type (MRI, CT, digital histopathology, etc) or research focus. DICOM is the primary file format used by TCIA for radiology imaging. Supporting data related to the images such as patient outcomes, treatment details, genomics and expert analyses are also provided when available.**\n",
    "\n",
    "Here, we have provided a series of methods to make requests to the TCIA API and download medical images of cancer available in their archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all the collections from the TCIA API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCollections():\n",
    "    '''Provides all the collections available in the Archive'''\n",
    "    baseurl = 'https://services.cancerimagingarchive.net/services/v3/TCIA'\n",
    "    queryEndpoint = '/query/getCollectionValues?'\n",
    "    queryParams = ''\n",
    "    form = 'format=json'\n",
    "    url = baseurl+queryEndpoint+queryParams+form\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    if response.status_code==200:\n",
    "        Collections = []\n",
    "        for dictionary in response.json():\n",
    "            Collections.append(dictionary['Collection'])\n",
    "        return Collections\n",
    "    else:\n",
    "        raise ValueError('Bad/No response')\n",
    "\n",
    "AllCollections = getCollections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map the Body part values affected by the collections name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/96 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### multiprocessing domain\n",
    "\n",
    "import gbp #the function py file\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "results = pool.map(gbp.getBodyPart,[c for c in AllCollections])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooledBodyPartAffected = dict(zip(AllCollections,results))\n",
    "BodyPartAffected = pooledBodyPartAffected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'BodyPartAffected' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store BodyPartAffected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r BodyPartAffected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the collections with only brain images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_collections():\n",
    "    '''returns only those collections where the body part affected is\n",
    "    either the brain or the lung'''\n",
    "    Collections_brain = []\n",
    "    Collections_lung  = []\n",
    "    for key,value in BodyPartAffected.items():\n",
    "        if len(value)==1:\n",
    "            if value[0] == 'BRAIN':\n",
    "                Collections_brain.append(key)\n",
    "            elif value[0] == 'LUNG':\n",
    "                Collections_lung.append(key)\n",
    "    return Collections_brain,Collections_lung\n",
    "\n",
    "brain,lungs = filter_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TCGA-LGG'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of the brain images collections, get the collections with clinical data and download the clinical data zip file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To be done by someone* here I am assuming that we got the TCGA-LGG zip file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of the clinical data, get the dataframes with vital status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nationwidechildrens.org_clinical_nte_lgg.txt\n",
      "nationwidechildrens.org_clinical_omf_v4.0_lgg.txt\n",
      "nationwidechildrens.org_clinical_patient_lgg.txt\n",
      "nationwidechildrens.org_clinical_radiation_lgg.txt\n",
      "nationwidechildrens.org_clinical_drug_lgg.txt\n",
      "nationwidechildrens.org_clinical_follow_up_v1.0_lgg.txt\n"
     ]
    }
   ],
   "source": [
    "zfile = 'TCGA-LGG Clinical Data 1516.zip'\n",
    "def getdfs(file):\n",
    "    with zipfile.ZipFile(file) as thezip:\n",
    "        dataframes = []\n",
    "        for filename in thezip.namelist():\n",
    "            print(filename)\n",
    "            data = pd.read_csv(thezip.open(filename),sep= '\\t',header=[0,1,2])\n",
    "            dataframes.append(data)\n",
    "        dataframes_valid = []\n",
    "    for i,j in enumerate(dataframes):\n",
    "        for column in j.columns:\n",
    "            if 'vital_status' in column:\n",
    "                dataframes_valid.append(j)\n",
    "    return dataframes_valid\n",
    "\n",
    "dfs = getdfs(zfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the dataframes, get the patient ids and their outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPatientID(df):\n",
    "    PIDS = []\n",
    "    for pid in df['bcr_patient_barcode'].values:\n",
    "        PIDS.append(pid[0])\n",
    "    labels = []\n",
    "    for label in df.loc[:,'vital_status'].values:\n",
    "        labels.append(label[0])\n",
    "    return PIDS,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PID,labels = getPatientID(dfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 197)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PID),len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the patient IDs and collections, get the series id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/197 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### multiprocessing domain\n",
    "\n",
    "import gSID #the function py file\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "results = pool.starmap(gSID.getSeriesID,[(pid,brain[3]) for pid in PID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooledpdict = {}\n",
    "\n",
    "for pid,label,sid in zip(PID,labels,results):\n",
    "    pooledpdict[pid] = {'label':label,'SerialIDs':sid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pooledpdict' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store pooledpdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r pooledpdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdict = pooledpdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the series ids, try to get the first five images in that series file\n",
    "\n",
    "*will try random 5 might be better*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 16min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### multiprocessing domain\n",
    "\n",
    "import gI #the function py file\n",
    "\n",
    "results = pool.map(gI.getImages,[pdict[pid]['SerialIDs'] for pid in PID])\n",
    "pool.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deeprob\\AppData\\Roaming\\Python\\Python36\\site-packages\\pydicom\\filereader.py:313: UserWarning: Expected explicit VR, but found implicit VR - using implicit VR for reading\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for pid,imgdata in zip(PID,results):\n",
    "    imagedataset = []\n",
    "    for f in imgdata:\n",
    "        try:\n",
    "            img = dcmread(DicomBytesIO(f))\n",
    "            imagedataset.append(img.pixel_array)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    pdict[pid]['images'] = imagedataset \n",
    "    pdict[pid]['image_count'] = len(imagedataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pdict' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store pdict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
